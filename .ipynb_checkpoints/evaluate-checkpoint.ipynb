{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f657afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os,sys\n",
    "sys.path.append('../')\n",
    "from os.path import join\n",
    "import glob\n",
    "import  random\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# from face2speaker_main import Face2Speaker\n",
    "# from Recode.model import DoubleLayerModel, SingleLayerModel\n",
    "from senet import *\n",
    "from model import *\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2069f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "class Evaluation():\n",
    "    def __init__(self, \n",
    "                root, \n",
    "                embedder,\n",
    "                num_queries=100, \n",
    "                gallery_size=5, \n",
    "                distance_metric='euclidean'):\n",
    "\n",
    "        self.embedder = embedder\n",
    "        self.root = root\n",
    "        self.gallery_size = gallery_size\n",
    "        self.num_queries = num_queries\n",
    "        self.distance_metric= distance_metric\n",
    "        self.generate_eval_data()\n",
    "        pass\n",
    "\n",
    "    def distance(self,a,b):\n",
    "        if self.distance_metric=='euclidean':\n",
    "            return np.linalg.norm(a-b)\n",
    "        elif self.distance_metric=='cosine':\n",
    "            return spatial.distance.cosine(a,b)\n",
    "\n",
    "    def generate_eval_data(self):\n",
    "        _id_list = sorted(os.listdir(self.root))\n",
    "\n",
    "        queries = []\n",
    "        final_gallery = []\n",
    "\n",
    "        for _id in sorted(os.listdir(self.root)):\n",
    "            _id_path = join(self.root, _id)\n",
    "            for _url in sorted(os.listdir(_id_path)):\n",
    "                _url_path = join(_id_path,_url)\n",
    "                listOfAud=[f for f in os.listdir(os.path.join(_url_path, \"audio\"))]\n",
    "                for aud in sorted(listOfAud):\n",
    "                    emb = join(_url_path, \"audio\", aud)\n",
    "                    queries.append(emb)\n",
    "        random.shuffle(queries)\n",
    "        for _idx, query in enumerate(queries[0:self.num_queries]):\n",
    "            _id = query.split(os.sep)[-4]\n",
    "            same_flag = 1\n",
    "\n",
    "            while same_flag:\n",
    "                answer_set = glob.glob(join(self.root, _id, join('*', \"frames\",'*.jpg')))\n",
    "\n",
    "                answer = random.choice(answer_set)\n",
    "                if(not answer.split(os.sep)[-3]==query.split(os.sep)[-3]):\n",
    "                    same_flag = 0\n",
    "                \n",
    "            diff_speakers = [i for i in _id_list if i!=_id]\n",
    "            random.shuffle(diff_speakers)\n",
    "\n",
    "            assert _id not in diff_speakers\n",
    "\n",
    "            impostor_gallery = [] \n",
    "            \n",
    "            for imp in diff_speakers[0:self.gallery_size-1]:\n",
    "                imp_embeddings = glob.glob(join(self.root,imp,join('*','frames', '*.jpg')))\n",
    "                impostor_gallery.append(random.choice(imp_embeddings))\n",
    "                \n",
    "            impostor_gallery.append(answer)\n",
    "            final_gallery.append(impostor_gallery)\n",
    "        print(np.array(queries).shape)    \n",
    "        self.queries = np.array(queries[0:self.num_queries])\n",
    "        self.galleries = np.array(final_gallery[0:self.num_queries])\n",
    "        self.answer = np.array([self.gallery_size-1]*self.num_queries)\n",
    "        # print(\"self.queries\", self.queries)\n",
    "        # print(\"self.galleries\", self.galleries)\n",
    "        print(\"Num queries : %d\"%(len(self.queries)))\n",
    "        print(\"Gallery Size : %d\"%(self.galleries.shape[1]))\n",
    "        pass\n",
    "\n",
    "    def evaluate(self):\n",
    "\n",
    "        test_samples = self.num_queries\n",
    "\n",
    "        result = []\n",
    "        \n",
    "        for _idx, query in enumerate(self.queries[0:test_samples]):\n",
    "            distances=[]\n",
    "            for toMatch in self.galleries[_idx]:\n",
    "                face_emb, audio_emb=self.embedder.get_embedding(input_path_pair=(toMatch, query))\n",
    "                distances.append(self.distance(face_emb, audio_emb))\n",
    "            result.append(np.argmin(distances))    \n",
    "            \n",
    "        result = np.array(result)\n",
    "        r = len(np.where(result==self.answer[0:test_samples])[0])\n",
    "        accuracy = r/test_samples\n",
    "        print(\"Identification Accuracy : %.4f\"%(accuracy))\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ada25723",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetEmbeddings():\n",
    "    def __init__(self, \n",
    "                 learnable_pins_model):\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.learnable_pins_model = learnable_pins_model \n",
    "        self.learnable_pins_model.to(self.device)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            self.learnable_pins_model = nn.DataParallel(self.learnable_pins_model) \n",
    "#         self.learnable_pins_model.module.test()\n",
    "        self.learnable_pins_model.eval()\n",
    "        \n",
    "    def get_embedding(self, input_path_pair=None, emb=None):\n",
    "        if input_path_pair[0] is not None and input_path_pair[1] is not None:\n",
    "            transformToTensor = transforms.ToTensor()         \n",
    "            face_frame = Image.open(input_path_pair[0]).convert('RGB')\n",
    "            audio_fft = np.load(input_path_pair[1])\n",
    "        img_transform = transforms.Compose([\n",
    "            # transforms.RandomHorizontalFlip(),\n",
    "            # transforms.ColorJitter(brightness=0.5, hue=0.3),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "#         display(face_frame)\n",
    "        face_frame = img_transform(face_frame).unsqueeze(0)\n",
    "        face_frame = face_frame.to(self.device)\n",
    "\n",
    "        audio_fft = transformToTensor(audio_fft).unsqueeze(0)\n",
    "        audio_fft = audio_fft.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            res_face_emb, res_audio_emb = self.learnable_pins_model(face_frame, audio_fft)\n",
    "        res_audio_emb = res_audio_emb.cpu().numpy().reshape(-1)\n",
    "        res_face_emb = res_face_emb.cpu().numpy().reshape(-1)\n",
    "\n",
    "        return res_face_emb, res_audio_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df891518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senet\n",
      "Weights Loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [01:41<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dfd06239fbf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtest_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/ssd_scratch/cvit/starc52/VoxCeleb2/test/mp4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/ssd_scratch/cvit/starc52/LPscheckpoints/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_e'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;31m#     dev_acc=run_evaluate(root=\"/ssd_scratch/cvit/starc52/VoxCeleb2/dev/mp4\", model_path=join('/ssd_scratch/cvit/starc52/LPscheckpoints_1/', 'model_e0.pth'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#     plt.plot(np.arange(0, len(test_acc))+2, test_acc, label=\"test\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-dfd06239fbf5>\u001b[0m in \u001b[0;36mrun_evaluate\u001b[0;34m(root, model_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0macc_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#     for i in tqdm(range(2, 11)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgallery_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_queries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m36237\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-84814ce114f0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, embedder, num_queries, gallery_size, distance_metric)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_queries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance_metric\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdistance_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_eval_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-84814ce114f0>\u001b[0m in \u001b[0;36mgenerate_eval_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mimp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiff_speakers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgallery_size\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mimp_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'frames'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mimpostor_gallery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimp_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/glob.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(pathname, recursive)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdirectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(pathname, recursive, dironly)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mglob_in_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_glob0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob_in_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_glob1\u001b[0;34m(dirname, pattern, dironly)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_glob1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_iterdir\u001b[0;34m(dirname, dironly)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdironly\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_evaluate(root=\"/scratch/starc52/VoxCeleb2/test/mp4/\", model_path=join('/ssd_scratch/cvit/starc52/LPscheckpoints/', 'model_e34.pth')):\n",
    "    test_root = root\n",
    "\n",
    "    model = LearnablePINSenetVggVox256(training=False)\n",
    "    model.test()\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "\n",
    "    embedder = GetEmbeddings(learnable_pins_model=model)\n",
    "\n",
    "\n",
    "    acc_arr = []\n",
    "#     for i in tqdm(range(2, 11)):\n",
    "    evaluation = Evaluation(root=test_root, embedder=embedder,gallery_size=2,num_queries=36237)\n",
    "\n",
    "    acc = evaluation.evaluate()\n",
    "    acc_arr.append(acc)\n",
    "\n",
    "    return acc_arr\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for i in tqdm(range(30, 37)):\n",
    "        test_acc=run_evaluate(root=\"/ssd_scratch/cvit/starc52/VoxCeleb2/test/mp4\", model_path=join('/ssd_scratch/cvit/starc52/LPscheckpoints/', 'model_e'+str(i)+'.pth'))\n",
    "#     dev_acc=run_evaluate(root=\"/ssd_scratch/cvit/starc52/VoxCeleb2/dev/mp4\", model_path=join('/ssd_scratch/cvit/starc52/LPscheckpoints_1/', 'model_e0.pth'))\n",
    "#     plt.plot(np.arange(0, len(test_acc))+2, test_acc, label=\"test\")\n",
    "#     plt.plot(np.arange(0, len(dev_acc))+2, dev_acc, label=\"dev\")\n",
    "#     plt.xlabel('Gallery Size')\n",
    "#     plt.ylabel('Identification Accuracy')\n",
    "#     plt.title('1:N F-V matching')\n",
    "#     plt.grid()\n",
    "#     plt.legend()\n",
    "#     plt.savefig('/home/starc52/audret/graphs/epoch_43.png')\n",
    "#     plt.clf()\n",
    "    # run_multiple_epochs(root=args.root)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
