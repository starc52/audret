{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c88232ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,sys\n",
    "sys.path.append('../')\n",
    "import glob\n",
    "import  random\n",
    "# import scipy\n",
    "# from scipy import spatial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "# from time import time \n",
    "from tqdm import tqdm\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from senet import *\n",
    "from model import *\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from time import strftime, time\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "random.seed(0)\n",
    "from senet50 import Senet50_ft_dag\n",
    "from resnet50 import Resnet50_ft_dag \n",
    "# from torch.utils.data import Dataset\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import tensorboardX\n",
    "import resnet50\n",
    "from os.path import join\n",
    "import pdb#; pdb.set_trace()\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9319487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 2048 #512 for Facenet, 2048 for VGGface2\n",
    "BATCHSIZE = 240\n",
    "NUM_WORKERS = 8\n",
    "ALPHA=0.6\n",
    "EPOCH_NUM=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4777e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleDataLoader(Dataset):\n",
    "\n",
    "    def __init__(self, root, split='train'):\n",
    "        self.root = root\n",
    "\n",
    "        missing = 0\n",
    "        speaker_list = sorted(os.listdir(root)) #/scratch/dev/VoxCeleb2/dev/mp4\n",
    "        self.samples_path=[]\n",
    "        print(\"Starting dataloading\")\n",
    "        for i, speaker_id in enumerate(speaker_list):\n",
    "            speaker_id_path = join(root, speaker_id)\n",
    "\n",
    "            for _url in sorted(os.listdir(speaker_id_path)):\n",
    "                url_path = join(speaker_id_path, _url)\n",
    "                listOfImages=[join(url_path, f) for f in os.listdir(url_path) if os.path.isfile(join(url_path, f)) and f[-4:]==\".jpg\"]\n",
    "                self.samples_path+=listOfImages\n",
    "\n",
    "        print(\"Total count %d, Split: %s\"%(len(self.samples_path), split))\n",
    "\n",
    "        if(split=='train'):\n",
    "            random.shuffle(self.samples_path)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        transformers=transforms.ToTensor()\n",
    "        face_frame_path = self.samples_path[idx]\n",
    "        \n",
    "        face_frame_teacher = Image.open(face_frame_path).convert('RGB')\n",
    "        face_frame_student = Image.open(face_frame_path).convert('RGB')\n",
    "        \n",
    "        teacher_transform = transforms.Compose([\n",
    "            transforms.Resize(224),  # smaller side resized\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.5, hue=0.3),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        student_transform = transforms.Compose([\n",
    "            transforms.Resize(224),  # smaller side resized\n",
    "            transforms.Resize(56),\n",
    "            transforms.Resize(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.5, hue=0.3),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        face_frame_teacher = teacher_transform(face_frame_teacher)\n",
    "        face_frame_student = student_transform(face_frame_student)\n",
    "        \n",
    "        return face_frame_teacher, face_frame_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c17df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Norm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(L2Norm, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x / torch.norm(x, dim=1, keepdim=True)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "155c2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGFace2Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                embedding_dim=4096,\n",
    "                arch_type='resnet'\n",
    "            ):\n",
    "        super(VGGFace2Model, self).__init__()\n",
    "        print(arch_type)\n",
    "        if arch_type=='resnet':\n",
    "            self.backbone = resnet50('/home/starc52/audret/resnet.pth')\n",
    "        else:\n",
    "            self.backbone = senet50('/home/starc52/audret/senet.pth')\n",
    "        \n",
    "        print(\"Weights Loaded!\")\n",
    "\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = True\n",
    "            # param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.backbone(x)[1]\n",
    "        x = x.view(batch_size, -1)\n",
    "        # x = self.fc(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da3b1867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(channel_in, channel_out, k_size, p_size, stride, dil):\n",
    "    layer = nn.Sequential(\n",
    "        nn.Conv2d(channel_in, channel_out, kernel_size=k_size, padding=p_size, stride=stride, dilation=dil),\n",
    "        nn.BatchNorm2d(channel_out),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "    return layer\n",
    "\n",
    "def linear_layer(size_in, size_out, l2=False):\n",
    "    if l2:\n",
    "        layer = nn.Sequential(\n",
    "            nn.Linear(size_in, size_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            L2Norm()\n",
    "        )\n",
    "        return layer\n",
    "    else:\n",
    "        layer = nn.Sequential(\n",
    "            nn.Linear(size_in, size_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b553bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallDistilledModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim=EMBEDDING_DIM):\n",
    "        super(SmallDistilledModel, self).__init__()\n",
    "        self.layer1 = conv_layer(3, 8, 4, 0, 2, 2) #Output:8, 109, 109\n",
    "        self.layer2 = conv_layer(8, 16, 4, 0, 2, 2) #Output:16, 52, 52\n",
    "        self.maxpool1 = nn.MaxPool2d(2) #Output: 16, 26, 26\n",
    "        self.layer3 = conv_layer(16, 32, 3, 1, 2, 1) #Output:32, 13, 13\n",
    "        self.maxpool2 = nn.MaxPool2d(2) #Output: 32, 6, 6\n",
    "        self.layer4 = conv_layer(32, 16, 1, 0, 1, 1) #Output:16, 6, 6\n",
    "        self.layer5 = conv_layer(16, 128, 3, 1, 1, 1) #Output:128, 6, 6\n",
    "        self.maxpool3 = nn.MaxPool2d(2) #Output: 128, 3, 3\n",
    "        self.layer6 = conv_layer(128, 32, 1, 0, 1, 1) #Output:32, 3, 3\n",
    "        self.layer7 = conv_layer(32, 256, 3, 1, 1, 1) #Output:256, 3, 3\n",
    "        self.maxpool4 = nn.MaxPool2d(2) #Output: 256, 1, 1\n",
    "        self.layer8 = conv_layer(256, 256, 1, 0, 1, 1) #Output:128, 1, 1\n",
    "        self.layer9 = conv_layer(256, EMBEDDING_DIM, 1, 0, 1, 1) #Output:embedding_dim, 1, 1\n",
    "\n",
    "        # self.layer3 = conv_layer(16, 64, 4, 0, 2, 1)\n",
    "        # self.layer4 = conv_layer(64, 128, 4, 0, 2, 1)\n",
    "        # self.flatten = nn.Flatten()\n",
    "#         self.linear1 = linear_layer(EMBEDDING_DIM, EMBEDDING_DIM, l2=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.maxpool1(x)\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.maxpool4(x)\n",
    "        \n",
    "        x = self.layer8(x)\n",
    "        x = self.layer9(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "#         x = self.linear1(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class CompleteDistillationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, aud_vis_model):\n",
    "        super(CompleteDistillationModel, self).__init__()\n",
    "        self.training=True\n",
    "        self.teacher_model = VGGFace2Model(arch_type=2048)\n",
    "        pretrained_dict = aud_vis_model.module.face_model.state_dict()\n",
    "        vgg_model_dict = self.teacher_model.state_dict()\n",
    "\n",
    "        # 1. filter out unnecessary keys\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in vgg_model_dict}\n",
    "        # 2. overwrite entries in the existing state dict\n",
    "        vgg_model_dict.update(pretrained_dict) \n",
    "        # 3. load the new state dict\n",
    "        self.teacher_model.load_state_dict(vgg_model_dict)\n",
    "        self.student_model = SmallDistilledModel(embedding_dim=EMBEDDING_DIM)\n",
    "        for param in self.teacher_model.parameters():\n",
    "            param.requires_grad=False\n",
    "        \n",
    "    def forward(self, teacher_images, student_images, tau=None):\n",
    "        emb_teachers = self.teacher_model(teacher_images)\n",
    "        emb_students = self.student_model(student_images)\n",
    "        return emb_teachers, emb_students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a7df19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senet\n",
      "Weights Loaded!\n",
      "2048\n",
      "Weights Loaded!\n",
      "SmallDistilledModel(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 8, kernel_size=(4, 4), stride=(2, 2), dilation=(2, 2))\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(4, 4), stride=(2, 2), dilation=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer4): Sequential(\n",
      "    (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer6): Sequential(\n",
      "    (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer7): Sequential(\n",
      "    (0): Conv2d(32, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (layer8): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer9): Sequential(\n",
      "    (0): Conv2d(256, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Starting dataloading\n",
      "Total count 337046, Split: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-13d82ff505be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0memb_teacher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_student\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudent_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_teacher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_student\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                                    \"them on device: {}\".format(self.src_device_obj, t.device))\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, inputs, kwargs, device_ids)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_kwargs\u001b[0;34m(inputs, kwargs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;34mr\"\"\"Scatter with support for kwargs dictionary\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(inputs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# None, clearing the cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mscatter_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, target_gpus, chunk_sizes, dim, input)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m# Perform CPU to GPU copies in a background stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mstreams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Synchronize with the copy stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstreams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/site-packages/torch/cuda/comm.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(tensor, devices, chunk_sizes, dim, streams)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "aud_vis_model_path=join('/ssd_scratch/cvit/starc52/LPscheckpoints_1','model_e47.pth')\n",
    "aud_vis_model = LearnablePINSenetVggVox256()\n",
    "aud_vis_model.test()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "aud_vis_model.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    aud_vis_model = nn.DataParallel(aud_vis_model)\n",
    "aud_vis_model.load_state_dict(torch.load(aud_vis_model_path)['model_state_dict'])\n",
    "\n",
    "\n",
    "model = CompleteDistillationModel(aud_vis_model)\n",
    "\n",
    "print(model.student_model)\n",
    "\n",
    "root = \"/ssd_scratch/cvit/starc52/VoxCeleb2/dev/mp4/\"\n",
    "LOG_PATH = '/home/starc52/LearnablePINs/train_log_'+str(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))+\"/\"\n",
    "CHECKPOINT_PATH = \"/ssd_scratch/cvit/starc52/distill_checkpoints/\"\n",
    "\n",
    "if os.path.isdir(CHECKPOINT_PATH):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(CHECKPOINT_PATH)\n",
    "\n",
    "\n",
    "TBoard = tensorboardX.SummaryWriter(log_dir=LOG_PATH)\n",
    "\n",
    "train = simpleDataLoader(root)\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=BATCHSIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "for epoch_num in tqdm(range(EPOCH_NUM)):\n",
    "    for iter_num, (teacher_images, student_images) in enumerate(trainloader):\n",
    "        step_num = epoch_num * len(trainloader) + iter_num\n",
    "        teacher_images, student_images = teacher_images.to(device, non_blocking=True), student_images.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        emb_teacher, emb_student = model(teacher_images, student_images)\n",
    "\n",
    "        loss = criterion(emb_teacher, emb_student)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        TBoard.add_scalar('Train/Loss', loss.item(), step_num)\n",
    "#         TBoard.add_histogram('teacher_images', emb_teacher, step_num)\n",
    "#         TBoard.add_histogram('student_images', emb_student, step_num)\n",
    "\n",
    "    torch.save({\n",
    "        'epoch':epoch_num,\n",
    "        'model_state_dict':model.state_dict(),\n",
    "        'optimizer_state_dict':optimizer.state_dict(),\n",
    "        'loss':loss,\n",
    "    }, os.path.join(CHECKPOINT_PATH, \"epoch_\"+str(epoch_num)+\".pth\"))\n",
    "    teacher_img = np.squeeze(np.reshape(teacher_images[0].cpu(), (-1, 3, 224, 224)))\n",
    "    student_img = np.squeeze(np.reshape(student_images[0].cpu(), (-1, 3, 224, 224)))\n",
    "    TBoard.add_image('teacher_images', teacher_img, step_num)\n",
    "    TBoard.add_image('student_images', student_img, step_num)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
