{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f657afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os,sys\n",
    "sys.path.append('../')\n",
    "from os.path import join\n",
    "import glob\n",
    "import  random\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# from face2speaker_main import Face2Speaker\n",
    "# from Recode.model import DoubleLayerModel, SingleLayerModel\n",
    "from senet import *\n",
    "from model import *\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62172d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_models():    \n",
    "    # getting the VGGFace_VGGM Learnable pins network\n",
    "    model_path=join('/ssd_scratch/cvit/starc52/LPscheckpoints','model_e49.pth')\n",
    "    model = LearnablePINSenetVggVox256()\n",
    "    model.test()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "    print(\"Loaded Original Model\")\n",
    "    \n",
    "    # getting the distilled model for replacing VGG face image branch\n",
    "    distill_model_path=join('/ssd_scratch/cvit/starc52/distill_checkpointsV2','epoch_9.pth')\n",
    "    distill_model = CompleteDistillationModel(model)\n",
    "    distill_model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    distill_model.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        distill_model = nn.DataParallel(distill_model)\n",
    "    distill_model.load_state_dict(torch.load(distill_model_path)['model_state_dict'])\n",
    "    print(\"Loaded Distilled Model\")\n",
    "    \n",
    "    # initiating the learnable pins network for distilled image branch weights\n",
    "    print(\"Scaffolding for Compressed Distilled model\")\n",
    "    comb_model = LearnablePINSdistill()\n",
    "    print(\"Getting face FC\")\n",
    "    pre_face_fc = model.module.face_fc.state_dict()\n",
    "    print(\"Getting audio branch\")\n",
    "    pre_audio_model = model.module.audio_model.state_dict()\n",
    "    print(\"Getting audio FC\")\n",
    "    pre_audio_fc = model.module.audio_fc.state_dict()\n",
    "    print(\"Getting compression distilled face branch\")\n",
    "    pre_distill_model = distill_model.module.student_model.state_dict()\n",
    "\n",
    "    comb_model_face_fc = comb_model.face_fc.state_dict()\n",
    "    comb_model_audio_model = comb_model.audio_model.state_dict()\n",
    "    comb_model_audio_fc = comb_model.audio_fc.state_dict()\n",
    "    comb_model_distill_model = comb_model.face_model.state_dict()\n",
    "\n",
    "    print(\"Loading face FC layer\")\n",
    "    pre_face_fc = {k: v for k, v in pre_face_fc.items() if k in comb_model_face_fc}\n",
    "    comb_model_face_fc.update(pre_face_fc) \n",
    "    comb_model.face_fc.load_state_dict(comb_model_face_fc)\n",
    "    \n",
    "    print(\"Loading audio branch layer\")\n",
    "    pre_audio_model = {k: v for k, v in pre_audio_model.items() if k in comb_model_audio_model}\n",
    "    comb_model_audio_model.update(pre_audio_model) \n",
    "    comb_model.audio_model.load_state_dict(comb_model_audio_model)\n",
    "\n",
    "    print(\"Loading audio FC layer\")\n",
    "    pre_audio_fc = {k: v for k, v in pre_audio_fc.items() if k in comb_model_audio_fc}\n",
    "    comb_model_audio_fc.update(pre_audio_fc) \n",
    "    comb_model.audio_fc.load_state_dict(comb_model_audio_fc)\n",
    "\n",
    "    print(\"Loading compression distilled face branch layer\")\n",
    "    pre_distill_model = {k: v for k, v in pre_distill_model.items() if k in comb_model_distill_model}\n",
    "    comb_model_distill_model.update(pre_distill_model) \n",
    "    comb_model.face_model.load_state_dict(comb_model_distill_model)\n",
    "    # returning the new learnable pins model\n",
    "    return comb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2069f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "class Evaluation():\n",
    "    def __init__(self, \n",
    "                root, \n",
    "                embedder,\n",
    "                num_queries=100, \n",
    "                gallery_size=5, \n",
    "                distance_metric='euclidean'):\n",
    "\n",
    "        self.embedder = embedder\n",
    "        self.root = root\n",
    "        self.gallery_size = gallery_size\n",
    "        self.num_queries = num_queries\n",
    "        self.distance_metric= distance_metric\n",
    "        self.generate_eval_data()\n",
    "        pass\n",
    "\n",
    "    def distance(self,a,b):\n",
    "        if self.distance_metric=='euclidean':\n",
    "            return np.linalg.norm(a-b)\n",
    "        elif self.distance_metric=='cosine':\n",
    "            return spatial.distance.cosine(a,b)\n",
    "\n",
    "    def generate_eval_data(self):\n",
    "        _id_list = sorted(os.listdir(self.root))\n",
    "\n",
    "        queries = []\n",
    "        final_gallery = []\n",
    "\n",
    "        for _id in sorted(os.listdir(self.root)):\n",
    "            _id_path = join(self.root, _id)\n",
    "            for _url in sorted(os.listdir(_id_path)):\n",
    "                _url_path = join(_id_path,_url)\n",
    "                listOfAud=[f for f in os.listdir(os.path.join(_url_path, \"audio\"))]\n",
    "                for aud in sorted(listOfAud):\n",
    "                    emb = join(_url_path, \"audio\", aud)\n",
    "                    queries.append(emb)\n",
    "        random.shuffle(queries)\n",
    "        for _idx, query in enumerate(queries[0:self.num_queries]):\n",
    "            _id = query.split(os.sep)[-4]\n",
    "            same_flag = 1\n",
    "\n",
    "            while same_flag:\n",
    "                answer_set = glob.glob(join(self.root, _id, join('*', \"frames\",'*.jpg')))\n",
    "\n",
    "                answer = random.choice(answer_set)\n",
    "                if(not answer.split(os.sep)[-3]==query.split(os.sep)[-3]):\n",
    "                    same_flag = 0\n",
    "                \n",
    "            diff_speakers = [i for i in _id_list if i!=_id]\n",
    "            random.shuffle(diff_speakers)\n",
    "\n",
    "            assert _id not in diff_speakers\n",
    "\n",
    "            impostor_gallery = [] \n",
    "            \n",
    "            for imp in diff_speakers[0:self.gallery_size-1]:\n",
    "                imp_embeddings = glob.glob(join(self.root,imp,join('*','frames', '*.jpg')))\n",
    "                impostor_gallery.append(random.choice(imp_embeddings))\n",
    "                \n",
    "            impostor_gallery.append(answer)\n",
    "            final_gallery.append(impostor_gallery)\n",
    "        print(np.array(queries).shape)    \n",
    "        self.queries = np.array(queries[0:self.num_queries])\n",
    "        self.galleries = np.array(final_gallery[0:self.num_queries])\n",
    "        self.answer = np.array([self.gallery_size-1]*self.num_queries)\n",
    "        # print(\"self.queries\", self.queries)\n",
    "        # print(\"self.galleries\", self.galleries)\n",
    "        print(\"Num queries : %d\"%(len(self.queries)))\n",
    "        print(\"Gallery Size : %d\"%(self.galleries.shape[1]))\n",
    "        pass\n",
    "\n",
    "    def evaluate(self):\n",
    "\n",
    "        test_samples = self.num_queries\n",
    "\n",
    "        result = []\n",
    "        \n",
    "        for _idx, query in enumerate(self.queries[0:test_samples]):\n",
    "            distances=[]\n",
    "            for gal, toMatch in enumerate(self.galleries[_idx]):\n",
    "                face_emb, audio_emb=self.embedder.get_embedding(input_path_pair=(toMatch, query))\n",
    "                distances.append(self.distance(face_emb, audio_emb))\n",
    "            result.append(np.argmin(distances))\n",
    "            \n",
    "        result = np.array(result)\n",
    "        r = len(np.where(result==self.answer[0:test_samples])[0])\n",
    "        accuracy = r/test_samples\n",
    "        print(\"Identification Accuracy : %.4f\"%(accuracy))\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ada25723",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetEmbeddings():\n",
    "    def __init__(self, \n",
    "                 learnable_pins_model, loss_factor):\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.loss_factor = loss_factor\n",
    "        self.learnable_pins_model = learnable_pins_model \n",
    "        self.learnable_pins_model.to(self.device)\n",
    "        self.learnable_pins_model.eval()\n",
    "        \n",
    "    def get_embedding(self, input_path_pair=None, emb=None):\n",
    "        if input_path_pair[0] is not None and input_path_pair[1] is not None:\n",
    "            transformToTensor = transforms.ToTensor()         \n",
    "            face_frame = Image.open(input_path_pair[0]).convert('RGB')\n",
    "            audio_fft = np.load(input_path_pair[1])\n",
    "        img_transform = transforms.Compose([\n",
    "            transforms.Resize((int(224 * self.loss_factor), int(224 * self.loss_factor)), interpolation=2),\n",
    "            transforms.Resize((224, 224), interpolation=2),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        face_frame = img_transform(face_frame).unsqueeze(0)\n",
    "        face_frame = face_frame.to(self.device)\n",
    "\n",
    "        audio_fft = transformToTensor(audio_fft).unsqueeze(0)\n",
    "        audio_fft = audio_fft.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            res_face_emb, res_audio_emb = self.learnable_pins_model(face_frame, audio_fft)\n",
    "        res_audio_emb = res_audio_emb.cpu().numpy().reshape(-1)\n",
    "        res_face_emb = res_face_emb.cpu().numpy().reshape(-1)\n",
    "\n",
    "        return res_face_emb, res_audio_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df891518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Factor:  0.05\n",
      "senet\n",
      "Weights Loaded!\n",
      "Loaded Original Model\n",
      "2048\n",
      "Weights Loaded!\n",
      "Loaded Distilled Model\n",
      "Scaffolding for Compressed Distilled model\n",
      "Getting face FC\n",
      "Getting audio branch\n",
      "Getting audio FC\n",
      "Getting compression distilled face branch\n",
      "Loading face FC layer\n",
      "Loading audio branch layer\n",
      "Loading audio FC layer\n",
      "Loading compression distilled face branch layer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9 [00:33<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/8 [00:36<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-705c303fac23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss Factor: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtest_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/ssd_scratch/cvit/starc52/VoxCeleb2/test/mp4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.55\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/ssd_scratch/cvit/starc52/LPscheckpoints/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_e49.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m#     dev_acc=run_evaluate(root=\"/ssd_scratch/cvit/starc52/VoxCeleb2/dev/mp4\", loss_factor=0.25, model_path=join('/ssd_scratch/cvit/starc52/LPscheckpoints/', 'model_e47.pth'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-705c303fac23>\u001b[0m in \u001b[0;36mrun_evaluate\u001b[0;34m(root, loss_factor, model_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0macc_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgallery_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_queries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m36237\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5daf9b00386f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, embedder, num_queries, gallery_size, distance_metric)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_queries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance_metric\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdistance_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_eval_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5daf9b00386f>\u001b[0m in \u001b[0;36mgenerate_eval_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msame_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0manswer_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"frames\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/glob.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(pathname, recursive)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mzero\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdirectories\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[0;34m(pathname, recursive, dironly)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mglob_in_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_glob0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob_in_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_glob1\u001b[0;34m(dirname, pattern, dironly)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_glob1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ishidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/p3ptch/lib/python3.7/glob.py\u001b[0m in \u001b[0;36m_iterdir\u001b[0;34m(dirname, dironly)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdironly\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_evaluate(root=\"/scratch/starc52/VoxCeleb2/test/mp4/\", loss_factor=0.25, model_path=join('/ssd_scratch/cvit/starc52/LPscheckpoints','model_e49.pth')):\n",
    "    test_root = root\n",
    "    \n",
    "    comb_model=combine_models()\n",
    "\n",
    "    embedder = GetEmbeddings(learnable_pins_model=comb_model, loss_factor=loss_factor)\n",
    "\n",
    "\n",
    "    acc_arr = []\n",
    "#     for i in tqdm(range(2, 11)):\n",
    "    evaluation = Evaluation(root=test_root, embedder=embedder,gallery_size=2,num_queries=36237)\n",
    "\n",
    "    acc = evaluation.evaluate()\n",
    "    acc_arr.append(acc)\n",
    "\n",
    "    return acc_arr\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for i in tqdm([0.05, 0.20, 0.25, 0.4, 0.5, 0.75, 0.95, 1]):\n",
    "        print(\"Loss Factor: \", i)\n",
    "        test_acc=run_evaluate(root=\"/ssd_scratch/cvit/starc52/VoxCeleb2/test/mp4\", loss_factor=0.55, model_path=join('/ssd_scratch/cvit/starc52/LPscheckpoints/', 'model_e49.pth'))\n",
    "    #     dev_acc=run_evaluate(root=\"/ssd_scratch/cvit/starc52/VoxCeleb2/dev/mp4\", loss_factor=0.25, model_path=join('/ssd_scratch/cvit/starc52/LPscheckpoints/', 'model_e47.pth'))\n",
    "        plt.plot(np.arange(0, len(test_acc))+2, test_acc, label=\"test\")\n",
    "        plt.plot(np.arange(0, len(dev_acc))+2, dev_acc, label=\"dev\")\n",
    "        plt.xlabel('Gallery Size')\n",
    "        plt.ylabel('Identification Accuracy')\n",
    "        plt.title('1:N F-V matching')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.savefig('/home/starc52/audret/graphs/epoch_43.png')\n",
    "        plt.clf()\n",
    "        # run_multiple_epochs(root=args.root)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
