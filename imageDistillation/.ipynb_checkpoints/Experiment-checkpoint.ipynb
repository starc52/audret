{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "194403d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os,sys\n",
    "sys.path.append('../')\n",
    "from os.path import join\n",
    "import glob\n",
    "import  random\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# from face2speaker_main import Face2Speaker\n",
    "# from Recode.model import DoubleLayerModel, SingleLayerModel\n",
    "from senet import *\n",
    "from model import *\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "from time import time\n",
    "\n",
    "# random.seed(0)\n",
    "random.seed(time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd676eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGFace2Model(nn.Module):\n",
    "\tdef __init__(self, \n",
    "\t\t\t\tembedding_dim=4096,\n",
    "\t\t\t\tarch_type='resnet'\n",
    "\t\t\t):\n",
    "\t\tsuper(VGGFace2Model, self).__init__()\n",
    "\t\tprint(arch_type)\n",
    "\t\tif arch_type=='resnet':\n",
    "\t\t\tself.backbone = resnet50('/home/starc52/audret/resnet.pth')\n",
    "\t\telse:\n",
    "\t\t\tself.backbone = senet50('/home/starc52/audret/senet.pth')\n",
    "\t\t\n",
    "\t\tprint(\"Weights Loaded!\")\n",
    "\n",
    "\t\tfor param in self.backbone.parameters():\n",
    "\t\t\tparam.requires_grad = True\n",
    "\t\t\t# param.requires_grad = False\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tbatch_size = x.size(0)\n",
    "\t\tx = self.backbone(x)[1]\n",
    "\t\tx = x.view(batch_size, -1)\n",
    "\t\t# x = self.fc(x)\n",
    "\t\t\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a003ee9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "senet\n",
      "Weights Loaded!\n",
      "senet\n",
      "Weights Loaded!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CompleteDistillationModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-79fdc8f5ef5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdistill_model_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/ssd_scratch/cvit/starc52/distill_checkpoints'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'epoch_1.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdistill_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompleteDistillationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdistill_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CompleteDistillationModel' is not defined"
     ]
    }
   ],
   "source": [
    "vgg_model = VGGFace2Model(arch_type='senet')\n",
    "model_path=join('/ssd_scratch/cvit/starc52/LPscheckpoints','model_e49.pth')\n",
    "model = LearnablePINSenetVggVox256()\n",
    "model.test()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(model_path)['model_state_dict'])\n",
    "\n",
    "distill_model_path=join('/ssd_scratch/cvit/starc52/distill_checkpoints','epoch_1.pth')\n",
    "distill_model = CompleteDistillationModel(model)\n",
    "distill_model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "distill_model.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    distill_model = nn.DataParallel(distill_model)\n",
    "distill_model.load_state_dict(torch.load(distill_model_path)['model_state_dict'])\n",
    "\n",
    "comb_model = LearnablePINSdistill()\n",
    "pre_face_fc = model.module.face_fc.state_dict()\n",
    "pre_audio_model = model.module.audio_model.state_dict()\n",
    "pre_audio_fc = model.module.audio_fc.state_dict()\n",
    "pre_distill_model = distill_model.module.student_model.state_dict()\n",
    "\n",
    "comb_model_face_fc = comb_model.face_fc.state_dict()\n",
    "comb_model_audio_model = comb_model.audio_model.state_dict()\n",
    "comb_model_audio_fc = comb_model.audio_fc.state_dict()\n",
    "comb_model_distill_model = comb_model.face_model.state_dict()\n",
    "\n",
    "\n",
    "# 1. filter out unnecessary keys\n",
    "pre_face_fc = {k: v for k, v in pre_face_fc.items() if k in comb_model_face_fc}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "comb_model_face_fc.update(pre_face_fc) \n",
    "# 3. load the new state dict\n",
    "comb_model.face_fc.load_state_dict(comb_model_face_fc)\n",
    "# 1. filter out unnecessary keys\n",
    "pre_audio_model = {k: v for k, v in pre_audio_model.items() if k in comb_model_audio_model}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "comb_model_audio_model.update(pre_audio_model) \n",
    "# 3. load the new state dict\n",
    "comb_model.audio_model.load_state_dict(comb_model_audio_model)\n",
    "# 1. filter out unnecessary keys\n",
    "pre_audio_fc = {k: v for k, v in pre_audio_fc.items() if k in comb_model_audio_fc}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "comb_model_audio_fc.update(pre_audio_fc) \n",
    "# 3. load the new state dict\n",
    "comb_model.audio_fc.load_state_dict(comb_model_audio_fc)\n",
    "\n",
    "# 1. filter out unnecessary keys\n",
    "pre_distill_model = {k: v for k, v in pre_distill_model.items() if k in comb_model_distill_model}\n",
    "# 2. overwrite entries in the existing state dict\n",
    "comb_model_distill_model.update(pre_distill_model) \n",
    "# 3. load the new state dict\n",
    "comb_model.face_model.load_state_dict(comb_model_distill_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
